{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgDvTblCpG6FJfsQ2BbEQ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraghasemi20/sentimentanalysis/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download([\"names\",\n",
        "\"stopwords\",\n",
        "\"state_union\",\n",
        "\"twitter_samples\",\n",
        "\"movie_reviews\",\n",
        "\"averaged_perceptron_tagger\",\n",
        "\"vader_lexicon\",\n",
        "\"punkt\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGvIfQeUiFdd",
        "outputId": "3a1bc4f5-1c27-4224-c54d-6b29c1db6caf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JIRTGD01MtLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
        "print(\"words = \",words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2aLvWMJjrPE",
        "outputId": "6d04fe47-3212-4afd-b627-0488f4b15ee6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words =  ['PRESIDENT', 'HARRY', 'S', 'TRUMAN', 'S', 'ADDRESS', 'BEFORE', 'A', 'JOINT', 'SESSION']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "words = [w for w in words if w.lower() not in stopwords]\n",
        "pprint.pp(words[:20],width=88,compact = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoIWL4Qfkg9T",
        "outputId": "6f0a884d-5e90-4082-9278-d3e8339a9a2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRESIDENT', 'HARRY', 'TRUMAN', 'ADDRESS', 'JOINT', 'SESSION', 'CONGRESS', 'April',\n",
            " 'Mr', 'Speaker', 'Mr', 'President', 'Members', 'Congress', 'heavy', 'heart', 'stand',\n",
            " 'friends', 'colleagues', 'Congress']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"For some quick analysis, creating a corpus could be overkill.\n",
        "If all you need is a word list,\n",
        "there are simpler ways to achieve that goal.\"\"\"\n",
        "pprint.pp(nltk.word_tokenize(text), width=79, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5cXo8Wzoj-U",
        "outputId": "6e0f585e-169b-4a38-fe85-4fb08b416ba5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
            " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
            " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words: list[str] = nltk.word_tokenize(text)\n",
        "fd = nltk.FreqDist(words)"
      ],
      "metadata": {
        "id": "t5_rfWOXpgpc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fd.most_common(10))\n",
        "fd.tabulate(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrB8CyQ_p_4v",
        "outputId": "96370343-ffec-4db9-97c2-5ecc0858b8f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 2), ('a', 2), ('.', 2), ('For', 1), ('some', 1), ('quick', 1), ('analysis', 1), ('creating', 1), ('corpus', 1), ('could', 1)]\n",
            "       ,        a        .      For     some    quick analysis creating   corpus    could \n",
            "       2        2        2        1        1        1        1        1        1        1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fd[\"America\"])\n",
        "print(fd[\"america\"])\n",
        "print(fd[\"AMERICA\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YBEMd9nqqLn",
        "outputId": "f57fb919-5241-4557-983b-45f636246a5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lower_fd = nltk.FreqDist([w.lower() for w in fd])"
      ],
      "metadata": {
        "id": "78DuY33RroX-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(nltk.corpus.state_union.words())\n",
        "text.concordance(\"america\", lines=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pFtobo2r1HU",
        "outputId": "1fa15e15-0072-4c92-a20a-fc0a54ca45e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 1079 matches:\n",
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n",
            "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
            " to make complete victory certain , America will never become a party to any pl\n",
            "nly in law and in justice . Here in America , we have labored long and hard to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concordance_list = text.concordance_list(\"america\", lines=2)\n",
        "for entry in concordance_list:\n",
        "  print(entry.line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp_fMxWrsOqx",
        "outputId": "4c6ccad4-3296-4bc1-e729-24090f753d8b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word1: list[str] = nltk.word_tokenize(\"\"\"Beautiful is better than ugly.\n",
        "Explicit is better than implicit.\n",
        "Simple is better than complex.\"\"\"\n",
        ")\n",
        "text1 = nltk.Text(word1)\n",
        "fd1 = text1.vocab()\n",
        "fd1.tabulate(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLAdyJQHuB62",
        "outputId": "93071620-a8fc-4d8d-f7b5-2385d758cc38"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    is better   than \n",
            "     3      3      3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
        "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"
      ],
      "metadata": {
        "id": "O66sb08pvmIo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finder.ngram_fd.most_common(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK8vQq7_wJal",
        "outputId": "edb48485-37bb-4d3c-c818-216a48dcac7d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('the', 'United', 'States'), 294),\n",
              " (('the', 'American', 'people'), 185),\n",
              " (('of', 'the', 'world'), 154)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finder.ngram_fd.tabulate(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FagiHRP8wSxb",
        "outputId": "02f8cc45-ad1c-4ba7-b7fb-b4e755338416"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ('the', 'United', 'States') ('the', 'American', 'people')        ('of', 'the', 'world') \n",
            "                          294                           185                           154 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sent = SentimentIntensityAnalyzer()\n",
        "result = sent.polarity_scores(\"Wow, NLTK is really powerful!\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kvtylpp1KR1",
        "outputId": "5d1edcd1-549c-4191-ab83-cd95b5e615d3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
      ],
      "metadata": {
        "id": "fatVZBzt3QiD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "def is_positive(tweet: str) -> bool:\n",
        "  \"\"\"True is tweet has positive compound sentiment, False otherwise.\"\"\"\n",
        "  return sent.polarity_scores(tweet)[\"compound\"] > 0\n",
        "##############################################################################\n",
        "shuffle(tweets)\n",
        "for tweet in tweets[:10]:\n",
        "  print(is_positive(tweet),\"->\",tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5vslHAS3v1i",
        "outputId": "b8c59e7e-6857-4e80-9214-b02778c9fe12"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True -> RT @EtonOldBoys: Mirror Poll Who came off best on Leaders' Question Time?#bbcqt\n",
            "Ed Miliband - 71%\n",
            "David Cameron - 25%\n",
            "Nick Clegg - 4%  http…\n",
            "True -> RT @JMchools: Nice try Ed but Scotland is still voting #SNP #UnionistScareTactics https//t.co/Pz7p4em8Iv\n",
            "True -> RT @JGForsyth: Clegg is right about that, he did put country before party and I suspect that history will treat him kindly for that reason\n",
            "True -> New Blog! An Important Life Lesson I learnt from watching this movie :) Something that everyone needs to remember! xx\n",
            "http//t.co/gco9IJqdcT\n",
            "False -> RT @Number10cat: In the usual #bbcqt slot the BBC is showing 30 minutes of just Nigel Farage; not sure I'll be able to tell the difference.…\n",
            "True -> @briones198 always makes things better :)❤️\n",
            "False -> RT @HumzaYousaf: That sound you hear is the final nail hammered into New Labour coffin as Ed Miliband says he'd rather let Tories in than w…\n",
            "True -> RT @NicolaSturgeon: If Miliband is going to let Tories in rather than work with SNP, we will definitely need lots of SNP MPs to protect Sco…\n",
            "False -> RT @theSNP: Miliband's indication he'd rather let Tories back into power than work with SNP piles pressure on Scottish Labour - http//t.co…\n",
            "False -> RT @Foxgoose: BBC anchor who led attack on Farage tonight was previously paid £000s by Labour council to chair anti-cuts meeting\n",
            "http//t.c…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
        "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
        "all_review_ids = positive_review_ids + negative_review_ids"
      ],
      "metadata": {
        "id": "vLRqLFyE43Jz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "def is_positive(review_id: str) -> bool:\n",
        "  \"\"\"True if the average of all sentences compound scores is positive.\"\"\"\n",
        "  text = nltk.corpus.movie_reviews.raw(review_id)\n",
        "  scores = [\n",
        "      sent.polarity_scores(sentences)[\"compound\"]\n",
        "      for sentences in nltk.sent_tokenize(text)\n",
        "  ]\n",
        "  return mean(scores) > 0"
      ],
      "metadata": {
        "id": "F7de_n4J6CiP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle(all_review_ids)\n",
        "correct = 0\n",
        "for review_id in all_review_ids:\n",
        "  if is_positive(review_id):\n",
        "    if review_id in positive_review_ids:\n",
        "      correct += 1\n",
        "  else:\n",
        "    if review_id in negative_review_ids:\n",
        "      correct += 1\n",
        "print(F\"{correct / len(all_review_ids):.2%} correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_UcGWmf7Ic0",
        "outputId": "2b55d91f-b421-4ce4-8fde-7cd48e46d7b5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.00% correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
        "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
        "#################################################################\n",
        "def skip_unwanted(pos_tuple):\n",
        "  word, tag = pos_tuple\n",
        "  if not word.isalpha() or word in unwanted:\n",
        "    return False\n",
        "  if tag.startswith(\"NN\"):\n",
        "    return False\n",
        "  return True\n",
        "###############################################################\n",
        "positive_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
        ")]\n",
        "negative_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
        ")]"
      ],
      "metadata": {
        "id": "HI5Pswif8H3q"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_fd = nltk.FreqDist(positive_words)\n",
        "negative_fd = nltk.FreqDist(negative_words)\n",
        "common_set = set(positive_fd).intersection(negative_fd)\n",
        "for word in common_set:\n",
        "  del positive_fd[word]\n",
        "  del negative_fd[word]\n",
        "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
        "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
      ],
      "metadata": {
        "id": "KNnE8elaAWr9"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#####################################################################\n",
        "stopwords = set(stopwords.words('english'))\n",
        "unwanted = stopwords.union(set(w.lower() for w in nltk.corpus.names.words()))\n",
        "####################################################################\n",
        "def is_valid_word(word):\n",
        "    return word.isalpha() and word.lower() not in unwanted\n",
        "###################################################################\n",
        "positive_words = [w for w in movie_reviews.words(categories=[\"pos\"]) if is_valid_word(w)]\n",
        "negative_words = [w for w in movie_reviews.words(categories=[\"neg\"]) if is_valid_word(w)]\n",
        "###################################################################\n",
        "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(positive_words)\n",
        "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(negative_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNwuRKwgC-SV",
        "outputId": "a2ce057f-9119-4430-fb8e-7a999ead3b21"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from statistics import mean\n",
        "\n",
        "def extract_features(text):\n",
        "    features = dict()\n",
        "    wordcount = 0\n",
        "    compound_scores = list()\n",
        "    positive_scores = list()\n",
        "    sent = nltk.sentiment.SentimentIntensityAnalyzer()\n",
        "\n",
        "    for sentence in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sentence):\n",
        "            if word.lower() in top_100_positive:  # Assuming top_100_positive is defined somewhere\n",
        "                wordcount += 1\n",
        "        compound_scores.append(sent.polarity_scores(sentence)[\"compound\"])\n",
        "        positive_scores.append(sent.polarity_scores(sentence)[\"pos\"])\n",
        "\n",
        "    if compound_scores:\n",
        "        features[\"mean_compound\"] = mean(compound_scores) + 1\n",
        "    else:\n",
        "        features[\"mean_compound\"] = 0  # Handle case when no scores are available\n",
        "\n",
        "    # Calculate mean positive score (assuming positive_scores is not empty)\n",
        "    if positive_scores:\n",
        "        features[\"mean_positive\"] = mean(positive_scores)\n",
        "    else:\n",
        "        features[\"mean_positive\"] = 0  # Handle case when no scores are available\n",
        "\n",
        "    features[\"wordcount\"] = wordcount\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "OGiAEYtoGGN0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
        "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
        "]\n",
        "features.extend([\n",
        "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
        "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
        "])"
      ],
      "metadata": {
        "id": "MEqJyij9JLap"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count = len(features) // 4\n",
        "shuffle(features)\n",
        "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
        "classifier.show_most_informative_features(10)\n",
        "print(\"#################################\")\n",
        "nltk.classify.accuracy(classifier, features[train_count:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfVQbC7VKOhQ",
        "outputId": "ba7984e5-edde-4680-ba02-0d3a51c4adc2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "               wordcount = 3                 pos : neg    =     10.0 : 1.0\n",
            "               wordcount = 2                 pos : neg    =      3.7 : 1.0\n",
            "               wordcount = 0                 neg : pos    =      1.6 : 1.0\n",
            "               wordcount = 1                 pos : neg    =      1.1 : 1.0\n",
            "           mean_positive = 0.09671052631578947    pos : neg    =      1.0 : 1.0\n",
            "#################################\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.674"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}